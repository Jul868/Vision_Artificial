[net]
# Testing
# batch=1
# subdivisions=1
# Training
batch=64 # Número de grupo de imagenes que va a tomar 
subdivisions=8 # Subdivisiones para cada proceso de entrenamiento 
# Al hacer el bacth y las subdivisiones más pequeñas, significa que tengo más capacidad de memoria 
width=416 # Redimencionar la imagen
height=416 # Redimencionar la imagen
channels=3 # Canales de la imagen (3 para RGB -> a color)
momentum=0.9 
decay=0.0005 # Decaimiento -> Regularización
angle=0 # Ángulo de rotación
saturation = 1.2 # Saturación
exposure = 1.2 # Exposición
hue=.1 # Tono

learning_rate=0.001 # El aprendizaje de un modelo siempre debe empezar con un valor pequeño
burn_in=1000
max_batches = 10200
policy=steps
steps=6000,8000 # En el paso 6000 y 8000 se va a reducir el learning rate (60% y 80% del max_batches)
scales=.1,.1

# Capas convolucionales 
# En las capas iniciales extare patrones simples y en las capas finales patrones más complejos
[convolutional]
batch_normalize=1
filters=16
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=1

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

###########

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=44 # Número de conectividad: (5 + número de clases) * número de máscaras -> (5 + 6) * 4 = 44
activation=linear

[yolo]
mask = 0,1,2,3 # Máscaras -> Se va a detectar en las capas 0,1,2,3 de los anchors 
anchors = 148,135, 132,198, 160,167, 160,198 # Cada par de números es un archor (148x135, 132x198, 160x167, 160x198)
                                             # Máximo 9 anchors
                                             # La primera capa de Yolo se encarga de detectar los objetos más pequeños 
                                             # El último anchor se creó con el valor más grande de cada dimensión
classes = 6 # Número de clases que se van a detectar
num = 4 # Número de anchors, debe coincidir con el número de masks
jitter=.3  # Aumentar la variabilidad de los datos -> cantidad de aleatoriedad
ignore_thresh = .7 # Si la confianza de la predicción es menor a 0.7, no se va a tener en cuenta
truth_thresh = 1 # Si la confianza de la predicción es mayor a 1, se va a tener en cuenta
random=1 # Aumentar la aleatoriedad, si esta en 1 se va a aumentar la aleatoriedad

[route]
layers = -4

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 8

[convolutional]
batch_normalize=1
filters=256 # 
size=3
stride=1
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=44
activation=linear

# Se tienen dos Yolos a considerar: es como si uno se encargara de aprender unos anchors específicos y el otro de otros anchors
# Se pueden tener más de un Yolo para tener más flexibilidad en la detección
# No necesariamente tienen que ser iguales las dos capaz de Yolo
[yolo]
mask = 0,1,2,3
anchors = 148,135, 132,198, 160,167, 160,198
classes = 6
num = 4
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1